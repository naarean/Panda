{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3 Maneras de Programar a una Red Neuronal - DOTCSV (https://www.youtube.com/watch?v=qTNUbPkR2ao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "\n",
    "# Creamos nuestros datos artificiales, donde buscaremos clasificar \n",
    "# dos anillos concéntricos de datos. \n",
    "X, Y = make_circles(n_samples=500, factor=0.5, noise=0.05)\n",
    "\n",
    "# Resolución del mapa de predicción.\n",
    "res = 100 \n",
    "\n",
    "# Coordendadas del mapa de predicción.\n",
    "_x0 = np.linspace(-1.5, 1.5, res)\n",
    "_x1 = np.linspace(-1.5, 1.5, res)\n",
    "\n",
    "# Input con cada combo de coordenadas del mapa de predicción.\n",
    "_pX = np.array(np.meshgrid(_x0, _x1)).T.reshape(-1, 2)\n",
    "\n",
    "# Objeto vacio a 0.5 del mapa de predicción.\n",
    "_pY = np.zeros((res, res)) + 0.5\n",
    "\n",
    "# Visualización del mapa de predicción.\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pcolormesh(_x0, _x1, _pY, cmap=\"coolwarm\", vmin=0, vmax=1)\n",
    "\n",
    "# Visualización de la nube de datos.\n",
    "plt.scatter(X[Y == 0,0], X[Y == 0,1], c=\"skyblue\")\n",
    "plt.scatter(X[Y == 1,0], X[Y == 1,1], c=\"salmon\")\n",
    "\n",
    "plt.tick_params(labelbottom=False, labelleft=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 / 1000 - Loss =  0.49661565 - Acc = 0.5\n",
      "Step 25 / 1000 - Loss =  0.49482414 - Acc = 0.5\n",
      "Step 50 / 1000 - Loss =  0.4895984 - Acc = 0.5\n",
      "Step 75 / 1000 - Loss =  0.45594263 - Acc = 0.5\n",
      "Step 100 / 1000 - Loss =  0.40900448 - Acc = 0.578\n",
      "Step 125 / 1000 - Loss =  0.39696082 - Acc = 0.592\n",
      "Step 150 / 1000 - Loss =  0.38536105 - Acc = 0.606\n",
      "Step 175 / 1000 - Loss =  0.37432188 - Acc = 0.62\n",
      "Step 200 / 1000 - Loss =  0.36443982 - Acc = 0.624\n",
      "Step 225 / 1000 - Loss =  0.35501593 - Acc = 0.632\n",
      "Step 250 / 1000 - Loss =  0.34331778 - Acc = 0.636\n",
      "Step 275 / 1000 - Loss =  0.32768303 - Acc = 0.64\n",
      "Step 300 / 1000 - Loss =  0.30749166 - Acc = 0.65\n",
      "Step 325 / 1000 - Loss =  0.28746393 - Acc = 0.656\n",
      "Step 350 / 1000 - Loss =  0.27069858 - Acc = 0.676\n",
      "Step 375 / 1000 - Loss =  0.2568091 - Acc = 0.758\n",
      "Step 400 / 1000 - Loss =  0.24383393 - Acc = 0.774\n",
      "Step 425 / 1000 - Loss =  0.23002467 - Acc = 0.782\n",
      "Step 450 / 1000 - Loss =  0.21607675 - Acc = 0.794\n",
      "Step 475 / 1000 - Loss =  0.20180711 - Acc = 0.808\n",
      "Step 500 / 1000 - Loss =  0.18832217 - Acc = 0.812\n",
      "Step 525 / 1000 - Loss =  0.17587665 - Acc = 0.816\n",
      "Step 550 / 1000 - Loss =  0.1666799 - Acc = 0.822\n",
      "Step 575 / 1000 - Loss =  0.16090551 - Acc = 0.826\n",
      "Step 600 / 1000 - Loss =  0.15689774 - Acc = 0.826\n",
      "Step 625 / 1000 - Loss =  0.1534487 - Acc = 0.828\n",
      "Step 650 / 1000 - Loss =  0.15004751 - Acc = 0.83\n",
      "Step 675 / 1000 - Loss =  0.14659171 - Acc = 0.834\n",
      "Step 700 / 1000 - Loss =  0.14303458 - Acc = 0.836\n",
      "Step 725 / 1000 - Loss =  0.13919842 - Acc = 0.836\n",
      "Step 750 / 1000 - Loss =  0.13502826 - Acc = 0.838\n",
      "Step 775 / 1000 - Loss =  0.13061637 - Acc = 0.848\n",
      "Step 800 / 1000 - Loss =  0.12606277 - Acc = 0.856\n",
      "Step 825 / 1000 - Loss =  0.121316954 - Acc = 0.866\n",
      "Step 850 / 1000 - Loss =  0.116224036 - Acc = 0.906\n",
      "Step 875 / 1000 - Loss =  0.11107759 - Acc = 0.92\n",
      "Step 900 / 1000 - Loss =  0.10588015 - Acc = 0.928\n",
      "Step 925 / 1000 - Loss =  0.10053387 - Acc = 0.934\n",
      "Step 950 / 1000 - Loss =  0.09504215 - Acc = 0.94\n",
      "Step 975 / 1000 - Loss =  0.089592814 - Acc = 0.942\n"
     ]
    }
   ],
   "source": [
    "#CON TENSORFLOW\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import animation\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# Definimos los puntos de entrada de la red, para la matriz X e Y.\n",
    "iX = tf.placeholder('float', shape=[None, X.shape[1]])\n",
    "iY = tf.placeholder('float', shape=[None])\n",
    "\n",
    "lr = 0.01           # learning rate\n",
    "nn = [2, 16, 8, 1]  # número de neuronas por capa.\n",
    "\n",
    "# Capa 1\n",
    "W1 = tf.Variable(tf.random_normal([nn[0], nn[1]]), name='Weights_1')\n",
    "b1 = tf.Variable(tf.random_normal([nn[1]]), name='bias_1')\n",
    "\n",
    "l1 = tf.nn.relu(tf.add(tf.matmul(iX, W1), b1))\n",
    "\n",
    "# Capa 2\n",
    "W2 = tf.Variable(tf.random_normal([nn[1], nn[2]]), name='Weights_2')\n",
    "b2 = tf.Variable(tf.random_normal([nn[2]]), name='bias_2')\n",
    "\n",
    "l2 = tf.nn.relu(tf.add(tf.matmul(l1, W2), b2))\n",
    "\n",
    "# Capa 3\n",
    "W3 = tf.Variable(tf.random_normal([nn[2], nn[3]]), name='Weights_3')\n",
    "b3 = tf.Variable(tf.random_normal([nn[3]]), name='bias_3')\n",
    "\n",
    "# Vector de predicciones de Y.\n",
    "pY = tf.nn.sigmoid(tf.add(tf.matmul(l2, W3), b3))[:, 0]\n",
    "\n",
    "\n",
    "# Evaluación de las predicciones.\n",
    "loss = tf.losses.mean_squared_error(pY, iY)\n",
    "\n",
    "# Definimos al optimizador de la red, para que minimice el error.\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.05).minimize(loss)\n",
    "\n",
    "n_steps = 1000 # Número de ciclos de entrenamiento.\n",
    "\n",
    "iPY = [] # Aquí guardaremos la evolución de las predicción, para la animación.\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  \n",
    "  # Inicializamos todos los parámetros de la red, las matrices W y b.\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "  # Iteramos n pases de entrenamiento.\n",
    "  for step in range(n_steps):\n",
    "  \n",
    "    # Evaluamos al optimizador, a la función de coste y al tensor de salida pY. \n",
    "    # La evaluación del optimizer producirá el entrenamiento de la red.\n",
    "    _, _loss, _pY = sess.run([optimizer, loss, pY], feed_dict={ iX : X, iY : Y })\n",
    "    \n",
    "    # Cada 25 iteraciones, imprimimos métricas.\n",
    "    if step % 25 == 0: \n",
    "      \n",
    "      # Cálculo del accuracy.\n",
    "      acc = np.mean(np.round(_pY) == Y)\n",
    "      \n",
    "      # Impresión de métricas.\n",
    "      print('Step', step, '/', n_steps, '- Loss = ', _loss, '- Acc =', acc)\n",
    "      \n",
    "      # Obtenemos predicciones para cada punto de nuestro mapa de predicción _pX.\n",
    "      _pY = sess.run(pY, feed_dict={ iX : _pX }).reshape((res, res))\n",
    "\n",
    "      # Y lo guardamos para visualizar la animación.\n",
    "      iPY.append(_pY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hq_admin15\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Epoch 1/100\n",
      "500/500 [==============================] - 0s 286us/sample - loss: 0.2544 - acc: 0.5060\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 0s 30us/sample - loss: 0.2530 - acc: 0.4460\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 0s 26us/sample - loss: 0.2517 - acc: 0.4540\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.2505 - acc: 0.4740\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.2494 - acc: 0.4820\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 0s 26us/sample - loss: 0.2484 - acc: 0.4860\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 0s 32us/sample - loss: 0.2472 - acc: 0.5200\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.2462 - acc: 0.4980\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 0s 30us/sample - loss: 0.2452 - acc: 0.4980\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 0s 26us/sample - loss: 0.2442 - acc: 0.5160\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 0s 32us/sample - loss: 0.2432 - acc: 0.5300\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 0s 30us/sample - loss: 0.2422 - acc: 0.5480\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.2412 - acc: 0.5560\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 0s 32us/sample - loss: 0.2401 - acc: 0.6020\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.2391 - acc: 0.6480\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 0s 30us/sample - loss: 0.2381 - acc: 0.6920\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.2371 - acc: 0.7060\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.2359 - acc: 0.7180\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.2349 - acc: 0.7240\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 0s 30us/sample - loss: 0.2337 - acc: 0.7420\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 0s 26us/sample - loss: 0.2325 - acc: 0.7260\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 0s 30us/sample - loss: 0.2312 - acc: 0.7560\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.2300 - acc: 0.7840\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 0s 26us/sample - loss: 0.2287 - acc: 0.7920\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 0s 26us/sample - loss: 0.2274 - acc: 0.8040\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 0s 26us/sample - loss: 0.2259 - acc: 0.8020\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 0s 26us/sample - loss: 0.2244 - acc: 0.8180\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.2229 - acc: 0.8320\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 0s 26us/sample - loss: 0.2212 - acc: 0.8420\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 0s 30us/sample - loss: 0.2196 - acc: 0.8680\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 0s 26us/sample - loss: 0.2178 - acc: 0.8720\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 0s 32us/sample - loss: 0.2160 - acc: 0.8820\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 0s 30us/sample - loss: 0.2139 - acc: 0.9040\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.2118 - acc: 0.9080\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 0s 34us/sample - loss: 0.2098 - acc: 0.9320\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.2075 - acc: 0.9240\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.2052 - acc: 0.9500\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 0s 30us/sample - loss: 0.2028 - acc: 0.9560\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.2004 - acc: 0.9640\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 0s 26us/sample - loss: 0.1977 - acc: 0.9780\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.1949 - acc: 0.9840\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 0s 32us/sample - loss: 0.1920 - acc: 0.9880\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.1891 - acc: 0.9920\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 0s 32us/sample - loss: 0.1860 - acc: 0.9960\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 0s 24us/sample - loss: 0.1828 - acc: 0.9960\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.1794 - acc: 0.9960\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 0s 30us/sample - loss: 0.1760 - acc: 0.9980\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.1725 - acc: 0.9980\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.1688 - acc: 0.9980\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 0s 32us/sample - loss: 0.1650 - acc: 0.9980\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 0s 30us/sample - loss: 0.1611 - acc: 0.9980\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.1571 - acc: 0.9980\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 0s 26us/sample - loss: 0.1530 - acc: 0.9980\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 0s 30us/sample - loss: 0.1489 - acc: 0.9980\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 0s 26us/sample - loss: 0.1447 - acc: 0.9980\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 0s 32us/sample - loss: 0.1404 - acc: 0.9980\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.1359 - acc: 0.9980\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 0s 46us/sample - loss: 0.1316 - acc: 0.9980\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.1273 - acc: 0.9980\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.1230 - acc: 0.9980\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.1187 - acc: 0.9980\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 0s 30us/sample - loss: 0.1143 - acc: 0.9980\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.1101 - acc: 0.9980\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 0s 26us/sample - loss: 0.1059 - acc: 0.9980\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.1017 - acc: 0.9980\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.0978 - acc: 0.9980\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 0s 26us/sample - loss: 0.0938 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 0s 26us/sample - loss: 0.0900 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.0863 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 0s 52us/sample - loss: 0.0827 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 0s 30us/sample - loss: 0.0792 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 0s 26us/sample - loss: 0.0758 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 0s 32us/sample - loss: 0.0726 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 0s 26us/sample - loss: 0.0695 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 0s 30us/sample - loss: 0.0665 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.0637 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 0s 32us/sample - loss: 0.0610 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 0s 30us/sample - loss: 0.0584 - acc: 1.0000\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0560 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.0536 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.0513 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 0s 32us/sample - loss: 0.0492 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.0472 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 0s 46us/sample - loss: 0.0452 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 0s 34us/sample - loss: 0.0435 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 0s 34us/sample - loss: 0.0417 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 0s 30us/sample - loss: 0.0401 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.0385 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 0s 34us/sample - loss: 0.0371 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.0356 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0344 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 0s 26us/sample - loss: 0.0330 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.0318 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.0307 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 0s 30us/sample - loss: 0.0297 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - 0s 32us/sample - loss: 0.0286 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 0s 30us/sample - loss: 0.0276 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 0s 34us/sample - loss: 0.0267 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 0s 28us/sample - loss: 0.0258 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0249 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x9248602dd8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##CON KERAS\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as kr\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "\n",
    "lr = 0.01           # learning rate\n",
    "nn = [2, 16, 8, 1]  # número de neuronas por capa.\n",
    "\n",
    "\n",
    "# Creamos el objeto que contendrá a nuestra red neuronal, como\n",
    "# secuencia de capas.\n",
    "model = kr.Sequential()\n",
    "\n",
    "# Añadimos la capa 1\n",
    "l1 = model.add(kr.layers.Dense(nn[1], activation='relu'))\n",
    "\n",
    "# Añadimos la capa 2\n",
    "l2 = model.add(kr.layers.Dense(nn[2], activation='relu'))\n",
    "\n",
    "# Añadimos la capa 3\n",
    "l3 = model.add(kr.layers.Dense(nn[3], activation='sigmoid'))\n",
    "\n",
    "# Compilamos el modelo, definiendo la función de coste y el optimizador.\n",
    "model.compile(loss='mse', optimizer=kr.optimizers.SGD(lr=0.05), metrics=['acc'])\n",
    "\n",
    "# Y entrenamos al modelo. Los callbacks \n",
    "model.fit(X, Y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.17902685\n",
      "Iteration 2, loss = 0.14316809\n",
      "Iteration 3, loss = 0.12737719\n",
      "Iteration 4, loss = 0.12533266\n",
      "Iteration 5, loss = 0.12617611\n",
      "Iteration 6, loss = 0.12570906\n",
      "Iteration 7, loss = 0.12512055\n",
      "Iteration 8, loss = 0.12498583\n",
      "Iteration 9, loss = 0.12514346\n",
      "Iteration 10, loss = 0.12516936\n",
      "Iteration 11, loss = 0.12504432\n",
      "Iteration 12, loss = 0.12506620\n",
      "Iteration 13, loss = 0.12516148\n",
      "Iteration 14, loss = 0.12509581\n",
      "Iteration 15, loss = 0.12509841\n",
      "Iteration 16, loss = 0.12506812\n",
      "Iteration 17, loss = 0.12504017\n",
      "Iteration 18, loss = 0.12510554\n",
      "Iteration 19, loss = 0.12511558\n",
      "Iteration 20, loss = 0.12507465\n",
      "Iteration 21, loss = 0.12507658\n",
      "Iteration 22, loss = 0.12504983\n",
      "Iteration 23, loss = 0.12503783\n",
      "Iteration 24, loss = 0.12516578\n",
      "Iteration 25, loss = 0.12519770\n",
      "Iteration 26, loss = 0.12502930\n",
      "Iteration 27, loss = 0.12504108\n",
      "Iteration 28, loss = 0.12506247\n",
      "Iteration 29, loss = 0.12504713\n",
      "Iteration 30, loss = 0.12506515\n",
      "Iteration 31, loss = 0.12508038\n",
      "Iteration 32, loss = 0.12517886\n",
      "Iteration 33, loss = 0.12512259\n",
      "Iteration 34, loss = 0.12503906\n",
      "Iteration 35, loss = 0.12508535\n",
      "Iteration 36, loss = 0.12518861\n",
      "Iteration 37, loss = 0.12504352\n",
      "Iteration 38, loss = 0.12503541\n",
      "Iteration 39, loss = 0.12514115\n",
      "Iteration 40, loss = 0.12503909\n",
      "Iteration 41, loss = 0.12511755\n",
      "Iteration 42, loss = 0.12507985\n",
      "Iteration 43, loss = 0.12503698\n",
      "Iteration 44, loss = 0.12506069\n",
      "Iteration 45, loss = 0.12525915\n",
      "Iteration 46, loss = 0.12505776\n",
      "Iteration 47, loss = 0.12512547\n",
      "Iteration 48, loss = 0.12513465\n",
      "Iteration 49, loss = 0.12511130\n",
      "Iteration 50, loss = 0.12505703\n",
      "Iteration 51, loss = 0.12502516\n",
      "Iteration 52, loss = 0.12504429\n",
      "Iteration 53, loss = 0.12510150\n",
      "Iteration 54, loss = 0.12506807\n",
      "Iteration 55, loss = 0.12510174\n",
      "Iteration 56, loss = 0.12504751\n",
      "Iteration 57, loss = 0.12508324\n",
      "Iteration 58, loss = 0.12519065\n",
      "Iteration 59, loss = 0.12509019\n",
      "Iteration 60, loss = 0.12525506\n",
      "Iteration 61, loss = 0.12504764\n",
      "Iteration 62, loss = 0.12512480\n",
      "Iteration 63, loss = 0.12505630\n",
      "Iteration 64, loss = 0.12505043\n",
      "Iteration 65, loss = 0.12505149\n",
      "Iteration 66, loss = 0.12504530\n",
      "Iteration 67, loss = 0.12509016\n",
      "Iteration 68, loss = 0.12505099\n",
      "Iteration 69, loss = 0.12501958\n",
      "Iteration 70, loss = 0.12503491\n",
      "Iteration 71, loss = 0.12505358\n",
      "Iteration 72, loss = 0.12507452\n",
      "Iteration 73, loss = 0.12503227\n",
      "Iteration 74, loss = 0.12503194\n",
      "Iteration 75, loss = 0.12506402\n",
      "Iteration 76, loss = 0.12502621\n",
      "Iteration 77, loss = 0.12505040\n",
      "Iteration 78, loss = 0.12502901\n",
      "Iteration 79, loss = 0.12513271\n",
      "Iteration 80, loss = 0.12504756\n",
      "Iteration 81, loss = 0.12505123\n",
      "Iteration 82, loss = 0.12502512\n",
      "Iteration 83, loss = 0.12507676\n",
      "Iteration 84, loss = 0.12506571\n",
      "Iteration 85, loss = 0.12505857\n",
      "Iteration 86, loss = 0.12506555\n",
      "Iteration 87, loss = 0.12507000\n",
      "Iteration 88, loss = 0.12506622\n",
      "Iteration 89, loss = 0.12513806\n",
      "Iteration 90, loss = 0.12508412\n",
      "Iteration 91, loss = 0.12517711\n",
      "Iteration 92, loss = 0.12502352\n",
      "Iteration 93, loss = 0.12509105\n",
      "Iteration 94, loss = 0.12505392\n",
      "Iteration 95, loss = 0.12507032\n",
      "Iteration 96, loss = 0.12502928\n",
      "Iteration 97, loss = 0.12504463\n",
      "Iteration 98, loss = 0.12503366\n",
      "Iteration 99, loss = 0.12508679\n",
      "Iteration 100, loss = 0.12508216\n",
      "Iteration 101, loss = 0.12503674\n",
      "Iteration 102, loss = 0.12508949\n",
      "Iteration 103, loss = 0.12505095\n",
      "Iteration 104, loss = 0.12508609\n",
      "Iteration 105, loss = 0.12505658\n",
      "Iteration 106, loss = 0.12502793\n",
      "Iteration 107, loss = 0.12530238\n",
      "Iteration 108, loss = 0.12509769\n",
      "Iteration 109, loss = 0.12505891\n",
      "Iteration 110, loss = 0.12515114\n",
      "Iteration 111, loss = 0.12508663\n",
      "Iteration 112, loss = 0.12504397\n",
      "Iteration 113, loss = 0.12504137\n",
      "Iteration 114, loss = 0.12506332\n",
      "Iteration 115, loss = 0.12504712\n",
      "Iteration 116, loss = 0.12507130\n",
      "Iteration 117, loss = 0.12504065\n",
      "Iteration 118, loss = 0.12508663\n",
      "Iteration 119, loss = 0.12502928\n",
      "Iteration 120, loss = 0.12506246\n",
      "Iteration 121, loss = 0.12510351\n",
      "Iteration 122, loss = 0.12511311\n",
      "Iteration 123, loss = 0.12508236\n",
      "Iteration 124, loss = 0.12502637\n",
      "Iteration 125, loss = 0.12507238\n",
      "Iteration 126, loss = 0.12505008\n",
      "Iteration 127, loss = 0.12504309\n",
      "Iteration 128, loss = 0.12505241\n",
      "Iteration 129, loss = 0.12506516\n",
      "Iteration 130, loss = 0.12504154\n",
      "Iteration 131, loss = 0.12516332\n",
      "Iteration 132, loss = 0.12508669\n",
      "Iteration 133, loss = 0.12505120\n",
      "Iteration 134, loss = 0.12503932\n",
      "Iteration 135, loss = 0.12510811\n",
      "Iteration 136, loss = 0.12507119\n",
      "Iteration 137, loss = 0.12505819\n",
      "Iteration 138, loss = 0.12503992\n",
      "Iteration 139, loss = 0.12504809\n",
      "Iteration 140, loss = 0.12511373\n",
      "Iteration 141, loss = 0.12507765\n",
      "Iteration 142, loss = 0.12508392\n",
      "Iteration 143, loss = 0.12503064\n",
      "Iteration 144, loss = 0.12503758\n",
      "Iteration 145, loss = 0.12504524\n",
      "Iteration 146, loss = 0.12509779\n",
      "Iteration 147, loss = 0.12511794\n",
      "Iteration 148, loss = 0.12504588\n",
      "Iteration 149, loss = 0.12509733\n",
      "Iteration 150, loss = 0.12511051\n",
      "Iteration 151, loss = 0.12507571\n",
      "Iteration 152, loss = 0.12506460\n",
      "Iteration 153, loss = 0.12525742\n",
      "Iteration 154, loss = 0.12506868\n",
      "Iteration 155, loss = 0.12511162\n",
      "Iteration 156, loss = 0.12511074\n",
      "Iteration 157, loss = 0.12504470\n",
      "Iteration 158, loss = 0.12509522\n",
      "Iteration 159, loss = 0.12510732\n",
      "Iteration 160, loss = 0.12513539\n",
      "Iteration 161, loss = 0.12507689\n",
      "Iteration 162, loss = 0.12506134\n",
      "Iteration 163, loss = 0.12502474\n",
      "Iteration 164, loss = 0.12502646\n",
      "Iteration 165, loss = 0.12503819\n",
      "Iteration 166, loss = 0.12504062\n",
      "Iteration 167, loss = 0.12509885\n",
      "Iteration 168, loss = 0.12509320\n",
      "Iteration 169, loss = 0.12507174\n",
      "Iteration 170, loss = 0.12508229\n",
      "Iteration 171, loss = 0.12507612\n",
      "Iteration 172, loss = 0.12503111\n",
      "Iteration 173, loss = 0.12511323\n",
      "Iteration 174, loss = 0.12505097\n",
      "Iteration 175, loss = 0.12512269\n",
      "Iteration 176, loss = 0.12512066\n",
      "Iteration 177, loss = 0.12511894\n",
      "Iteration 178, loss = 0.12519274\n",
      "Iteration 179, loss = 0.12508967\n",
      "Iteration 180, loss = 0.12507094\n",
      "Iteration 181, loss = 0.12505336\n",
      "Iteration 182, loss = 0.12504366\n",
      "Iteration 183, loss = 0.12506505\n",
      "Iteration 184, loss = 0.12502554\n",
      "Iteration 185, loss = 0.12506291\n",
      "Iteration 186, loss = 0.12505720\n",
      "Iteration 187, loss = 0.12503595\n",
      "Iteration 188, loss = 0.12502735\n",
      "Iteration 189, loss = 0.12506996\n",
      "Iteration 190, loss = 0.12504074\n",
      "Iteration 191, loss = 0.12507709\n",
      "Iteration 192, loss = 0.12506094\n",
      "Iteration 193, loss = 0.12506578\n",
      "Iteration 194, loss = 0.12504222\n",
      "Iteration 195, loss = 0.12502286\n",
      "Iteration 196, loss = 0.12521622\n",
      "Iteration 197, loss = 0.12501360\n",
      "Iteration 198, loss = 0.12505580\n",
      "Iteration 199, loss = 0.12508607\n",
      "Iteration 200, loss = 0.12506952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hq_admin15\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size=64, beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=(16, 8, 1), learning_rate='constant',\n",
       "             learning_rate_init=0.01, max_iter=200, momentum=0.9,\n",
       "             n_iter_no_change=1000, nesterovs_momentum=True, power_t=0.5,\n",
       "             random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Con Sklearn\n",
    "\n",
    "import sklearn as sk\n",
    "import sklearn.neural_network\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "lr = 0.01           # learning rate\n",
    "nn = [2, 16, 8, 1]  # número de neuronas por capa.\n",
    "\n",
    "# Creamos el objeto del modelo de red neuronal multicapa.\n",
    "clf = sk.neural_network.MLPRegressor(solver='sgd', \n",
    "                                     learning_rate_init=lr, \n",
    "                                     hidden_layer_sizes=tuple(nn[1:]),\n",
    "                                     verbose=True,\n",
    "                                     n_iter_no_change=1000,\n",
    "                                     batch_size = 64)\n",
    "\n",
    "# Y lo entrenamos con nuestro datos.\n",
    "clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
